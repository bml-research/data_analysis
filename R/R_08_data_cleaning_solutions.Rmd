![](../hanze/hanze.png)

[Go back to the main page](../index.html)

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# R

## Data Cleaning Solutions

```{r}
library(tidyverse)
```

```{r}
library(kableExtra)
formatted_table <- function(df){
  kbl(df) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"))
}
```

This file can be downloaded [here](./R_08_data_cleaning_solutions.Rmd)

### Exercise 1

[This](./files_07_data_cleaning_exercises/exercise01/calories.xlsx) first data set was not loaded well in Excel. Load the Excel file as a tibble in R. Separate the columns correctly.
Hint: use the `separate_wider_delim` function from tidyverse.

```{r}
library(readxl)
file_path <- "./files_07_data_cleaning_exercises/exercise01/calories.xlsx"
df <- read_excel(file_path)
colname <- "FoodCategory|FoodItem|per100grams|Cals_per100grams|KJ_per100grams"
df <- df %>% separate_wider_delim(colname, delim = "|", names = c("FoodCategory", "FoodItem", "per100grams", "Cals_per100grams", "KJ_per100grams"))
formatted_table(head(df))
```

### Exercise 2

The file from the previous exercise contains the units in the cells. This makes it impossible to perform calculations (as the data type is a text string). Remove the units in order to make calculations possible.

```{r}
df <- df %>% 
  separate_wider_delim(Cals_per100grams, delim = " ", names = c("Cals_per100grams", "waste")) %>% 
  separate_wider_delim(KJ_per100grams, delim = " ", names = c("KJ_per100grams", "waste2")) %>%
  select (-c(waste, waste2)) %>% #Note that this is a negative selection. Selects all but the listed columns.
  mutate_at(c('Cals_per100grams', 'KJ_per100grams'), as.numeric) #Creates numbers from strings
formatted_table(head(df))
```

### Exercise 3

[This](./files_07_data_cleaning_exercises/exercise03/Food Composition_mod.csv) data set contains rows with duplicate data. Load the data and remove the duplicates from the data table.

```{r}
file_path <- "./files_07_data_cleaning_exercises/exercise03/Food Composition_mod.csv"
df <- read_csv(file_path)
formatted_table(head(df, 1))
```

Let's first find duplicate elements in the columns:

```{r}
df$`Public Food Key`[duplicated(df$`Public Food Key`)]
```

```{r}
df$`Food Profile ID`[duplicated(df$`Food Profile ID`)]
```

Are they in the same rows?

```{r}
formatted_table(df[df$`Public Food Key` == "F009575", ])
```

```{r}
formatted_table(df[df$`Public Food Key` == "F006725", ])
```

Yes, they are in the same rows.
First count the number of rows:

```{r}
nrow(df)
```


Now we can delete the duplicated rows:

```{r}
my_data_cleaned <- df[!duplicated(df$`Public Food Key`), ]
formatted_table(head(my_data_cleaned, 1))
```

Note that there are 1561 rows in the above tibble. Two less compared to the beginning (1563).

```{r}
nrow(my_data_cleaned)
```


Check if we still have duplicated rows:

```{r}
my_data_cleaned$`Public Food Key`[duplicated(my_data_cleaned$`Public Food Key`)]
```

```{r}
my_data_cleaned$`Food Profile ID`[duplicated(my_data_cleaned$`Food Profile ID`)]
```

Both yielded an empty vector meaning the tibble does not contain duplicated rows anymore.

### Exercise 4

[This](./files_07_data_cleaning_exercises/exercise04/nutrition.csv) data set contains empty data.

Make the empty elements more explicit in R by converting them to `NA`.
Count how many elements you have:

- in total
- with missing data
- without missing data

```{r}
file_path <- "./files_07_data_cleaning_exercises/exercise04/nutrition.csv"
df <- read_csv(file_path)
formatted_table(head(df))
```

```{r}
paste("total elements:", nrow(df) * ncol(df))
paste("non empty elements:", sum(!is.na(df)))
paste("empty elements:", sum(is.na(df)))
```



---


>This web page is distributed under the terms of the Creative Commons Attribution License which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
>Creative Commons License: CC BY-SA 4.0.

